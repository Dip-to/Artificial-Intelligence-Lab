{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qVOPadXNgWhS",
    "outputId": "0df34ba8-adcf-4529-b292-c40980a6be7f"
   },
   "outputs": [],
   "source": [
    "#!pip3 install selenium arrow webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XktrFCnng2-X",
    "outputId": "d460e439-8fe0-427c-d891-7eceb1cb82f3"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01marrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m By\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msympy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m subsets\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "\n",
    "import dis\n",
    "from operator import contains\n",
    "import re\n",
    "import time\n",
    "from arrow import get\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from sympy import subsets\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fileClear():\n",
    "    file = open(\"links.txt\", \"w\")\n",
    "    file.write(\"\")\n",
    "    file.close()\n",
    "    file = open(\"text.txt\", \"a\")\n",
    "    file.write(\"\")\n",
    "    file.close()\n",
    "\n",
    "def fileAdd(data):\n",
    "    file = open(\"links.txt\", \"a\")\n",
    "    file.write(data + \"\\n\")\n",
    "    file.close()\n",
    "\n",
    "def fileAddText(data):\n",
    "    file = open(\"text.txt\", \"a\")\n",
    "    file.write(data + \"\\n\")\n",
    "    file.close()\n",
    "\n",
    "\n",
    "def is_subset(subset, string):\n",
    "    # Convert both the subset and the string to lowercase for case-insensitive matching\n",
    "    subset = subset.lower()\n",
    "    string = string.lower()\n",
    "\n",
    "    # Check if the subset is present in the string\n",
    "    return subset in string\n",
    "\n",
    "\n",
    "def scrape_pTag_text(driver):\n",
    "    pTag = driver.find_elements(By.TAG_NAME, \"p\")\n",
    "    text = \"\"\n",
    "    for tag in pTag:\n",
    "        text += tag.text\n",
    "    return text\n",
    "\n",
    "def get_all_links_with_selenium(url):\n",
    "    try:\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.set_page_load_timeout(10)\n",
    "        driver.get(url)\n",
    "        text = scrape_pTag_text(driver)\n",
    "        fileAddText(text)\n",
    "        elements = driver.find_elements(By.XPATH, \"//a[@href]\")\n",
    "        urls = []\n",
    "        for element in elements:\n",
    "            href = element.get_attribute(\"href\")\n",
    "            if href:\n",
    "                if not is_subset(\"google\",href) or is_subset(\"facebook\",href) or is_subset(\"youtube\",href) or is_subset(\"twitter\",href) or is_subset(\"instagram\",href) or is_subset(\"linkedin\",href) or is_subset(\"pinterest\",href) or is_subset(\"reddit\",href) or is_subset(\"tumblr\",href) or is_subset(\"amazon\",href) or is_subset(\"ebay\",href) or is_subset(\"yahoo\",href) or is_subset(\"bing\",href) or is_subset(\"netflix\",href) or is_subset(\"craigslist\",href) or is_subset(\"paypal\",href) or is_subset(\"wordpress\",href) or is_subset(\"apple\",href) or is_subset(\"microsoft\",href) or is_subset(\"adobe\",href):\n",
    "                    if href not in urls:\n",
    "                        urls.append(href)\n",
    "                        fileAdd(href)\n",
    "        time.sleep(1)\n",
    "        driver.quit()\n",
    "        return urls\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []\n",
    "\n",
    "\n",
    "# Example usage\n",
    "\n",
    "\n",
    "def googleSearch(search):\n",
    "    get_all_links_with_selenium('https://www.google.com/search?q=' + search)\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # search = input('What would you like to search on Google?\\n')\n",
    "    googleSearch(\"Dhaka\")\n",
    "\n",
    "\n",
    "# main()\n",
    "\n",
    "\n",
    "class link:\n",
    "    def __init__(self, link, parent, visited, depth):\n",
    "        self.link = link\n",
    "        self.parent = parent\n",
    "        self.visited = visited\n",
    "        self.depth = depth\n",
    "\n",
    "\n",
    "class Search:\n",
    "    def __init__(self):\n",
    "        self.linkset = set()\n",
    "        self.Graph = {}\n",
    "\n",
    "    def DFS(self, graph, node, visited = None, distance=0):\n",
    "        if distance > 3:\n",
    "            return\n",
    "        distance += 1\n",
    "        if visited is None:\n",
    "            visited = set()\n",
    "        if node not in visited:\n",
    "\n",
    "            visited.add(node)\n",
    "            urls = get_all_links_with_selenium(node)\n",
    "            print(node, distance)\n",
    "            if urls:\n",
    "                print(urls[0])\n",
    "            graph[node] = urls\n",
    "            for neighbour in graph[node]:\n",
    "                self.DFS(graph, neighbour, visited, distance)\n",
    "        return visited\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "my_graph = Search()\n",
    "\n",
    "\n",
    "start_node = 'https://www.google.com/search?q='+input('What would you like to search on Google?\\n')\n",
    "print(\"DFS starting from node\", start_node)\n",
    "fileClear()\n",
    "my_graph.Graph = {start_node: []}\n",
    "visited = None\n",
    "my_graph.DFS(my_graph.Graph, start_node )\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
